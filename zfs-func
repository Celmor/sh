# to source in bashrc

# pools to sync/compare between:
pool=( Data DataBackup DataNew )
# log file for stderror of zfs command
log=/tmp/zfs.log
# zfs wrapper function so stderr of zfs command doesn't 'flood' terminal
# for example if used wrong in which case stderr gets redirected to $log
zfs(){
        command zfs 2> >(
                read -r && printf '%s\n' "$REPLY" >&2
                read -r && [ ! -z "$REPLY" ] \
                && printf 'more error output in "%s"\n' "$log" >&2 \
                && printf '\n%s\n' "[$(date --rfc-3339=seconds)]" >> "$log" \
                && printf '%s\n' "$REPLY" >> "$log"; cat >> "$log"
        )
}
# get pool name/root dir of a dataset/folder
getPool(){
        [ $# -ne 1 ] || [ -z "$1" ] && return 1
        [ "$(dirname "$1")" = "/" ] || [ "$(dirname "$1")" = "." ] \
        && printf '%s\n' "$1" && return 0
        printf '%s\n' "$(getPool "$(dirname "$1")")"
}
# compare $1 (which is a dir) between pools; choosing pool of $1 as master
comparePool(){
        [ $# -ne 1 ] || [ -z "$1" ] \
        && printf 'Usage: %s <filesystem>' "$0" && return 1
        root="$(getPool "$1")"; root=${root///}
        for i in "${pool[@]}"; do [ "$root" = "$i" ] && continue
        printf 'comparing "%s" -> %s:\n' "$root" "$i"
        sudo rsync -axHAXS --delete -i --dry-run "$1"/ /"$i${1//"/$root"}"/
        done
}
# sync $1 (which is a dir) between pools; choosing pool of $1 as master
syncPool(){
        [ $# -ne 1 ] || [ -z "$1" ] \
        && printf 'Usage: %s <filesystem>' "$0" && return 1
        root="$(getPool "$1")"; root=${root///}
        for i in "${pool[@]}"; do [ "$root" = "$i" ] && continue
        printf 'comparing "%s" -> %s:\n' "$root" "$i"
        sudo rsync -axHAXS -i --delete "$1/" /"$i${1//"/$root"}"/
        done
}
# moves a single DATASET from SOURCE pool into DEST (dataset)
zfs-send(){
        [ $EUID == 0 ] || { echo "This function must be run as root"; return 1; }
	dataset="$1"
        source="$2"
        dest"$3"
	snapshot1="$(zfs list -Ho name -t snapshot -d 1 -r "$dataset" | head -1)"
	snapshot2="$(zfs list -Ho name -t snapshot -d 1 -r "$dataset" | tail -1)"
	attr=( compression mountpoint sharenfs exec setuid acltype xattr sharesmb )
	parameter=()
	for i in "${attr[@]}"; do value="$(zfs get -Ho value "$i" "$dataset")"; [ "$value" = "-" ] && continue; parameter+=("-o"); parameter+=("$i=$value"); done
	zfs send -cL "$snapshot1" | zfs recv -uv "${parameter[@]}" "$(i="${dataset//"$source"/"$dest"}"; echo "${i%@*}")"
	[ "$snapshot1" != "$snapshot2" ] && \
	zfs send -cLI "$snapshot1" "$snapshot2" | zfs recv -uv "${parameter[@]}" "$(i="${dataset//"$source"/"$dest"}"; echo "${i%@*}")"
}
# destroys only dataset including all its snapshots, throws error if there are other children
zfs-destroy(){
	zfs list -Ht snapshot -o name -d 1 -r "$1" | while read -r snapshot; do zfs destroy "$snapshot"; done && zfs destroy "$1"
}
